{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "- train the example RBP model\n",
    "  - nothing fancy\n",
    "  - no concise dependencies \n",
    "  - just single-task for simplicity - PUM2\n",
    "- export the model to .json and weights to hdf5  \n",
    "\n",
    "## TODO \n",
    "\n",
    "- [ ] check how is it with the pre-processing\n",
    "  - Raw bed + fasta + gtf-> array\n",
    "    - sequence as 1-hot\n",
    "    - distances\n",
    "- [ ]\n",
    "\n",
    "## Structure\n",
    "\n",
    "Input files:\n",
    "\n",
    "- fasta\n",
    "- Bed\n",
    "- annotation GTF\n",
    "\n",
    "Input features:\n",
    "\n",
    "- 1-hot-encoded sequence\n",
    "- annotation features & distances\n",
    "\n",
    "I will start with the batch preprocessor (loading the whole dataset at once) and then add a generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open questions\n",
    "\n",
    "- difference between genomelake and genomedatalayer?\n",
    "- I really like genomelake - it should become the standard for the pre-processors\n",
    "  - should be simple enough to use and understand\n",
    "  - add nearest feature-point extractor\n",
    "- test_files should be raw files not already pre-processed folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processor steps\n",
    "\n",
    "- Given range extract the sequence from the fasta file\n",
    "  - Validate the width (or just extract the center)\n",
    "  - compute the center range for it\n",
    "  - pybed tools\n",
    "    - [...] check the kundaje-lab code for this task\n",
    "\n",
    "- Load-in the GTF file and compute the distances to the nearest features\n",
    "  - [ ] see the programming possibilities for doing this in python\n",
    "  - see 4_append_other_positions.R\n",
    "  - just use pandas.DataFrame for it\n",
    "    - Idea: include it into concise as a pre-processor\n",
    "    \n",
    "- Why are they not using HTSeq?    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from concise.preprocessing import encodeDNA, EncodeSplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import concise.layers as cl\n",
    "import keras.layers as kl\n",
    "import concise.initializers as ci\n",
    "import concise.regularizers as cr\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO - path = ~/projects-work/concise/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(split=\"train\", st=None):\n",
    "    dt = pd.read_csv(\"../data/RBP/PUM2_{0}.csv\".format(split))\n",
    "    # DNA/RNA sequence\n",
    "    xseq = encodeDNA(dt.seq) \n",
    "    # distance to the poly-A site\n",
    "    xpolya = dt.polya_distance.as_matrix().reshape((-1, 1))\n",
    "    # response variable\n",
    "    y = dt.binding_site.as_matrix().reshape((-1, 1)).astype(\"float\")\n",
    "    return {\"seq\": xseq, \"dist_polya_raw\": xpolya}, y\n",
    "\n",
    "def data():\n",
    "    \n",
    "    train, valid, test = load(\"train\"), load(\"valid\"), load(\"test\")\n",
    "    \n",
    "    # transform the poly-A distance with B-splines\n",
    "    es = EncodeSplines()\n",
    "    es.fit(train[0][\"dist_polya_raw\"])\n",
    "    train[0][\"dist_polya_st\"] = es.transform(train[0][\"dist_polya_raw\"])\n",
    "    valid[0][\"dist_polya_st\"] = es.transform(valid[0][\"dist_polya_raw\"])\n",
    "    test[0][\"dist_polya_st\"] = es.transform(test[0][\"dist_polya_raw\"])\n",
    "    \n",
    "    #return load(\"train\"), load(\"valid\"), load(\"test\")\n",
    "    return train, valid, test\n",
    "\n",
    "train, valid, test = data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(train, filters=1, kernel_size=9, pwm_list=None, lr=0.001, use_splinew=True, ext_dist=False):\n",
    "    seq_length = train[0][\"seq\"].shape[1]\n",
    "    if pwm_list is None:\n",
    "        kinit = \"glorot_uniform\"\n",
    "        binit = \"zeros\"\n",
    "    else:\n",
    "        kinit = ci.PSSMKernelInitializer(pwm_list, add_noise_before_Pwm2Pssm=True)\n",
    "        binit = \"zeros\"\n",
    "        \n",
    "    # sequence\n",
    "    in_dna = cl.InputDNA(seq_length=seq_length, name=\"seq\")\n",
    "    inputs = [in_dna]\n",
    "    x = cl.ConvDNA(filters=filters, \n",
    "                   kernel_size=kernel_size, \n",
    "                   activation=\"relu\",\n",
    "                   kernel_initializer=kinit,\n",
    "                   bias_initializer=binit,\n",
    "                   name=\"conv1\")(in_dna)\n",
    "    if use_splinew:\n",
    "        x = cl.SplineWeight1D(n_bases=10, l2_smooth=0, l2=0, name=\"spline_weight\")(x)\n",
    "        x = kl.GlobalAveragePooling1D()(x)\n",
    "    else:\n",
    "        x = kl.AveragePooling1D(pool_size=4)(x)\n",
    "        x = kl.Flatten()(x)\n",
    "        \n",
    "    if ext_dist:    \n",
    "        # distance\n",
    "        in_dist = kl.Input(train[0][\"dist_polya_st\"].shape[1:], name=\"dist_polya_st\")\n",
    "        x_dist = cl.SplineT()(in_dist)\n",
    "        x = kl.concatenate([x, x_dist])\n",
    "        inputs += [in_dist]\n",
    "    \n",
    "    x = kl.Dense(units=1)(x)\n",
    "    m = Model(inputs, x)\n",
    "    m.compile(Adam(lr=lr), loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = model(train, filters=10, use_splinew=False, ext_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.fit(train[0], train[1], epochs=50, validation_data=valid, \n",
    "     callbacks=[EarlyStopping(patience=5)])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
